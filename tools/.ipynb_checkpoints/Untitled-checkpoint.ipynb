{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1928c0-f127-41d1-b08b-6e3dfb253e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "\n",
    "# move into the root directory to find my data module\n",
    "os.chdir('/Users/narayanmurti/Workspace/Dissertation')\n",
    "sys.path.append(os.getcwd())\n",
    "from data.citypersons import CitypersonsDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def collate_function(data):\n",
    "    return tuple(zip(*data))\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    # Read the config file #\n",
    "    with open(args.config_path, 'r') as file:\n",
    "        try:\n",
    "            config = yaml.safe_load(file)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    print(config)\n",
    "    ########################\n",
    "\n",
    "    dataset_config = config['dataset_params']\n",
    "    train_config = config['train_params']\n",
    "\n",
    "    seed = train_config['seed']\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    citypersons = CitypersonsDataset(split = 'train',\n",
    "                     im_dir=dataset_config['im_train_path'],\n",
    "                     ann_file=dataset_config['ann_train_path'])\n",
    "\n",
    "    train_dataset = DataLoader(citypersons,\n",
    "                               batch_size=4,\n",
    "                               shuffle=True,\n",
    "                               num_workers=0,\n",
    "                               collate_fn=collate_function)\n",
    "\n",
    "    if args.use_resnet50_fpn:\n",
    "        faster_rcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True,\n",
    "                                                                                 min_size=600,\n",
    "                                                                                 max_size=1000,\n",
    "        )\n",
    "        faster_rcnn_model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "            faster_rcnn_model.roi_heads.box_predictor.cls_score.in_features,\n",
    "            num_classes=21)\n",
    "    else:\n",
    "        backbone = torchvision.models.resnet34(pretrained=True, norm_layer=torchvision.ops.FrozenBatchNorm2d)\n",
    "        backbone = torch.nn.Sequential(*list(backbone.children())[:-3])\n",
    "        backbone.out_channels = 256\n",
    "        roi_align = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)\n",
    "        rpn_anchor_generator = AnchorGenerator()\n",
    "        faster_rcnn_model = torchvision.models.detection.FasterRCNN(backbone,\n",
    "                                                                    num_classes=21,\n",
    "                                                                    min_size=600,\n",
    "                                                                    max_size=1000,\n",
    "                                                                    rpn_anchor_generator=rpn_anchor_generator,\n",
    "                                                                    rpn_pre_nms_top_n_train=12000,\n",
    "                                                                    rpn_pre_nms_top_n_test=6000,\n",
    "                                                                    box_batch_size_per_image=128,\n",
    "                                                                    rpn_post_nms_top_n_test=300\n",
    "                                                                    )\n",
    "\n",
    "    faster_rcnn_model.train()\n",
    "    faster_rcnn_model.to(device)\n",
    "    if not os.path.exists(train_config['task_name']):\n",
    "        os.mkdir(train_config['task_name'])\n",
    "\n",
    "    optimizer = torch.optim.SGD(lr=1E-4,\n",
    "                                params=filter(lambda p: p.requires_grad, faster_rcnn_model.parameters()),\n",
    "                                weight_decay=5E-5, momentum=0.9)\n",
    "\n",
    "    num_epochs = train_config['num_epochs']\n",
    "    step_count = 0\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        rpn_classification_losses = []\n",
    "        rpn_localization_losses = []\n",
    "        frcnn_classification_losses = []\n",
    "        frcnn_localization_losses = []\n",
    "        for ims, targets, _ in tqdm(train_dataset):\n",
    "            optimizer.zero_grad()\n",
    "            for target in targets:\n",
    "                target['boxes'] = target['bboxes'].float().to(device)\n",
    "                del target['bboxes']\n",
    "                target['labels'] = target['labels'].long().to(device)\n",
    "            images = [im.float().to(device) for im in ims]\n",
    "            batch_losses = faster_rcnn_model(images, targets)\n",
    "            loss = batch_losses['loss_classifier']\n",
    "            loss += batch_losses['loss_box_reg']\n",
    "            loss += batch_losses['loss_rpn_box_reg']\n",
    "            loss += batch_losses['loss_objectness']\n",
    "\n",
    "            rpn_classification_losses.append(batch_losses['loss_objectness'].item())\n",
    "            rpn_localization_losses.append(batch_losses['loss_rpn_box_reg'].item())\n",
    "            frcnn_classification_losses.append(batch_losses['loss_classifier'].item())\n",
    "            frcnn_localization_losses.append(batch_losses['loss_box_reg'].item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step_count +=1\n",
    "        print('Finished epoch {}'.format(i))\n",
    "        if args.use_resnet50_fpn:\n",
    "            torch.save(faster_rcnn_model.state_dict(), os.path.join(train_config['task_name'],\n",
    "                                                                    'tv_frcnn_r50fpn_' + train_config['ckpt_name']))\n",
    "        else:\n",
    "            torch.save(faster_rcnn_model.state_dict(), os.path.join(train_config['task_name'],\n",
    "                                                                    'tv_frcnn_' + train_config['ckpt_name']))\n",
    "        loss_output = ''\n",
    "        loss_output += 'RPN Classification Loss : {:.4f}'.format(np.mean(rpn_classification_losses))\n",
    "        loss_output += ' | RPN Localization Loss : {:.4f}'.format(np.mean(rpn_localization_losses))\n",
    "        loss_output += ' | FRCNN Classification Loss : {:.4f}'.format(np.mean(frcnn_classification_losses))\n",
    "        loss_output += ' | FRCNN Localization Loss : {:.4f}'.format(np.mean(frcnn_localization_losses))\n",
    "        print(loss_output)\n",
    "    print('Done Training...')\n",
    "\n",
    "\n",
    "#THIS IS FOR RUNNING ON THE COMMAND LINE\n",
    "#if __name__ == '__main__':\n",
    "#    parser = argparse.ArgumentParser(description='Arguments for faster rcnn using torchvision code training')\n",
    "#    parser.add_argument('--config', dest='config_path',\n",
    "#                        default='config/citypersons.yaml', type=str)\n",
    "#    parser.add_argument('--use_resnet50_fpn', dest='use_resnet50_fpn',\n",
    "#                        default=True, type=bool)\n",
    "#    args = parser.parse_args(args=[] if sys.argv[0].endswith('ipykernel_launcher.py') else sys.argv[1:])\n",
    "#    train(args)\n",
    "\n",
    "\n",
    "#THIS IS FOR RUNNING IN JUPYTER\n",
    "# Manually define the arguments instead of using argparse\n",
    "class Args:\n",
    "    config_path = 'config/citypersons.yaml'\n",
    "    use_resnet50_fpn = True  # or False\n",
    "\n",
    "args = Args()\n",
    "train(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorvch_env",
   "language": "python",
   "name": "pytorvch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
